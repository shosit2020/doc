# 联合国CGF“促进人工智能算法性别平等”项目启动

[![返回目录](http://img.shields.io/badge/点击-返回目录-875A7B.svg?style=flat&colorA=8F8F8F)](/)

----------

## 摘要

以“让数据科技服务于人的福祉和自由”为使命的玛娜数据基金会由此发起了“促进人工智能算法性别平等”项目，便是针对人工智能时代性别平等问题的新特征、新趋势进行的探索。该项目获得了联合国-中国社会性别研究和倡导基金(CGF)第九批项目支持。

项目负责人首先列举了人脸识别、智能招聘、金融等领域中人工智能算法性别歧视的案例，然后借助社会建构论、社会数据化和技术女性主义等理论框架分析人工智能算法性别歧视的两大根源所在，即社会性别的影响进一步固化到算法之中、人工智能技术创新中的“女性视角”缺失。最后提出四大行动纲领：道德算法、算法透明：建立算法审查和评估机制，向用户做到算法可解释、引入算法设计的女性视角、打破固有性别歧视，以及基础研究和学术倡导、开展能力建设和政策与社会倡导等主要干预措施。

## 分析

算法作为人工智能的核心,带给人类机遇的同时也带来了一些风险, 在其实际应用过程中往往会出现偏差性结论或反馈,其中最为典型的是“算法歧视”现象愈发严重，对某一类社会群体无形中造成不平等的对待，譬如案例中提到的性别偏见。因此,当算法歧视与人类理性价值发生碰撞时,所带来的问题值得我们警醒。

“算法歧视”一方面根源于人类固有的社会偏见的反映，另一方面，数据也是关键变量之一，主要来自于数据采集的片面性。为克服算法歧视带来的不良后果，我们不仅应当基于禁止歧视或平等保护目的建立一套对AI算法的伦理审查标准体系，还应增强智能算法的透明性。

正如丹妮拉·济慈·西特伦在其论文《技术正当程序》中所指出的，“鉴于智能算法日益决定着各种决策的结果，人们需要建构技术公平规范体系，通过程序设计来保障公平的实现，并借助于技术程序的正当性来强化智能决策系统的透明性、可审查性和可解释性”。



## 图片

![图片](5.1.1.jpg)
![图片](5.1.2.jpg)

## 标签

性别平等（SDG5）



----------

 [![上一个](http://img.shields.io/badge/查看-上一个-875A7B.svg?style=flat&colorA=8F8F8F)](https://doc.shanghaiopen.org.cn/case/4/3.html)
 [![下一个](http://img.shields.io/badge/查看-下一个-875A7B.svg?style=flat&colorA=8F8F8F)](https://doc.shanghaiopen.org.cn/case/6/1.html)
 
 
